{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading BERT model... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "loading CLIP model... done\n",
      "DEVICE:  cuda\n",
      "loading dataset:  4D_100k_imgs_sf ...done\n",
      "raw X: (100000, 953) \tY: (100000, 160)\n",
      "filtered X: (96771, 953) \tY: (96771, 160)\n",
      "Train X: (67739, 953) \tY: (67739, 160)\n",
      "Test  X: (19355, 953) \tY: (19355, 160)\n",
      "Val   X: (9677, 953) \tY: (9677, 160)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import numpy as np\n",
    "from src.motion_refiner_4D import Motion_refiner, MAX_NUM_OBJS\n",
    "from src.config import *\n",
    "from src.functions import *\n",
    "\n",
    "mr = Motion_refiner(load_models=True ,traj_n = traj_n, locality_factor=True, clip_only=False)\n",
    "feature_indices, obj_sim_indices, obj_poses_indices, traj_indices = mr.get_indices()\n",
    "embedding_indices = mr.embedding_indices\n",
    "\n",
    "#============================== load dataset ==========================================\n",
    "X,Y, data = mr.load_dataset(dataset_name, filter_data = True, base_path=data_folder)\n",
    "X_train, X_test, X_valid, y_train, y_test, y_valid, indices_train, indices_test, indices_val = mr.split_dataset(X, Y, test_size=0.2, val_size=0.1)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((mr.prepare_x(X_test),\n",
    "                                                    list_to_wp_seq(y_test,d=4),\n",
    "                                                    X_test[:,embedding_indices])).batch(X_test.shape[0])\n",
    "\n",
    "g = generator(test_dataset,stop=True,augment=False)\n",
    "x_t, y_t = next(g)\n",
    "\n",
    "#==============================0000000000000==========================================\n",
    "def evaluate_model(model, x_t, y_t):\n",
    "\n",
    "    print(\"\\nwith next waypoint prediction\")\n",
    "    result_eval = model.evaluate(x_t,y_t)\n",
    "    print(\"MSE: \",result_eval)\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"with autoregressive generation:\")\n",
    "\n",
    "    pred = generate(model ,x_t, traj_n=traj_n).numpy()\n",
    "    result_gen = np.average((y_t - pred[:,1:,:])**2)\n",
    "    print(\"MSE: \",result_gen)\n",
    "    print(\"Trajectory metrics:\")\n",
    "    metrics, metrics_h = compute_metrics(y_t.numpy()[:,:,:3],pred[:,1:,:3])\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset size experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================\n",
      "Dataset size:  1.0 %\t augmentation:  OFF \n",
      "\n",
      "{'num_layers_enc': 1, 'num_layers_dec': 5, 'd_model': 400, 'dff': 512, 'num_heads': 8, 'dropout_rate': 0.1, 'wp_d': 4, 'num_emb_vec': 4, 'bs': 16, 'dense_n': 512, 'num_dense': 3, 'concat_emb': False, 'features_n': 793, 'optimizer': 'adam', 'norm_layer': True, 'activation': 'tanh', 'loss': 'mse', 'sf': 0.01, 'augment': 0}\n",
      "loading weights:  /home/azureuser/data/models/ICRA_TF4D_dataset_size_aug/TF-num_layers_enc:1-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:0.01-augment:0.h5\n",
      "\n",
      "with next waypoint prediction\n",
      "605/605 [==============================] - 16s 23ms/step - loss: 0.0011\n",
      "MSE:  0.001147542498074472\n",
      "---------------------------------------------------\n",
      "with autoregressive generation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [07:24<00:00, 11.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.04642006029187642\n",
      "Trajectory metrics:\n",
      "pcm:\t nan\n",
      "dfd:\t 0.4855052467987429\n",
      "area:\t 0.11811484325016983\n",
      "cl:\t nan\n",
      "dtw:\t 9.907811929425844\n",
      "mae:\t 0.14150047427352047\n",
      "mse:\t 0.03781905153733537\n",
      "======================================================================================================\n",
      "Dataset size:  1.0 %\t augmentation:  ON  \n",
      "\n",
      "{'num_layers_enc': 1, 'num_layers_dec': 5, 'd_model': 400, 'dff': 512, 'num_heads': 8, 'dropout_rate': 0.1, 'wp_d': 4, 'num_emb_vec': 4, 'bs': 16, 'dense_n': 512, 'num_dense': 3, 'concat_emb': False, 'features_n': 793, 'optimizer': 'adam', 'norm_layer': True, 'activation': 'tanh', 'loss': 'mse', 'sf': 0.01, 'augment': 1}\n",
      "loading weights:  /home/azureuser/data/models/ICRA_TF4D_dataset_size_aug/TF-num_layers_enc:1-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:0.01-augment:1.h5\n",
      "\n",
      "with next waypoint prediction\n",
      "605/605 [==============================] - 16s 22ms/step - loss: 9.0490e-04\n",
      "MSE:  0.0009083700715564191\n",
      "---------------------------------------------------\n",
      "with autoregressive generation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [07:18<00:00, 11.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.04445634728509167\n",
      "Trajectory metrics:\n",
      "pcm:\t nan\n",
      "dfd:\t 0.4822911294821316\n",
      "area:\t 0.12010433962268263\n",
      "cl:\t nan\n",
      "dtw:\t 9.707516932851473\n",
      "mae:\t 0.14041032651210336\n",
      "mse:\t 0.03730230580838904\n",
      "======================================================================================================\n",
      "Dataset size:  10.0 %\t augmentation:  OFF \n",
      "\n",
      "{'num_layers_enc': 1, 'num_layers_dec': 5, 'd_model': 400, 'dff': 512, 'num_heads': 8, 'dropout_rate': 0.1, 'wp_d': 4, 'num_emb_vec': 4, 'bs': 16, 'dense_n': 512, 'num_dense': 3, 'concat_emb': False, 'features_n': 793, 'optimizer': 'adam', 'norm_layer': True, 'activation': 'tanh', 'loss': 'mse', 'sf': 0.1, 'augment': 0}\n",
      "loading weights:  /home/azureuser/data/models/ICRA_TF4D_dataset_size_aug/TF-num_layers_enc:1-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:0.1-augment:0.h5\n",
      "\n",
      "with next waypoint prediction\n",
      "605/605 [==============================] - 16s 22ms/step - loss: 1.3217e-04\n",
      "MSE:  0.00013212136400397867\n",
      "---------------------------------------------------\n",
      "with autoregressive generation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [07:17<00:00, 11.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.0023591018726528044\n",
      "Trajectory metrics:\n",
      "pcm:\t nan\n",
      "dfd:\t 0.06292330351780735\n",
      "area:\t 0.02514266134960972\n",
      "cl:\t nan\n",
      "dtw:\t 1.4234632817518555\n",
      "mae:\t 0.019508433972043535\n",
      "mse:\t 0.001199093305479409\n",
      "======================================================================================================\n",
      "Dataset size:  10.0 %\t augmentation:  ON  \n",
      "\n",
      "{'num_layers_enc': 1, 'num_layers_dec': 5, 'd_model': 400, 'dff': 512, 'num_heads': 8, 'dropout_rate': 0.1, 'wp_d': 4, 'num_emb_vec': 4, 'bs': 16, 'dense_n': 512, 'num_dense': 3, 'concat_emb': False, 'features_n': 793, 'optimizer': 'adam', 'norm_layer': True, 'activation': 'tanh', 'loss': 'mse', 'sf': 0.1, 'augment': 1}\n",
      "loading weights:  /home/azureuser/data/models/ICRA_TF4D_dataset_size_aug/TF-num_layers_enc:1-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:0.1-augment:1.h5\n",
      "\n",
      "with next waypoint prediction\n",
      "605/605 [==============================] - 16s 22ms/step - loss: 1.2320e-04\n",
      "MSE:  0.0001223062427015975\n",
      "---------------------------------------------------\n",
      "with autoregressive generation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [07:17<00:00, 11.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.002223579699245976\n",
      "Trajectory metrics:\n",
      "pcm:\t nan\n",
      "dfd:\t 0.05313825742322576\n",
      "area:\t 0.02192462795033975\n",
      "cl:\t nan\n",
      "dtw:\t 1.2487861897980428\n",
      "mae:\t 0.016873071055151227\n",
      "mse:\t 0.0008171283799243248\n",
      "======================================================================================================\n",
      "Dataset size:  100.0 %\t augmentation:  OFF \n",
      "\n",
      "{'num_layers_enc': 1, 'num_layers_dec': 5, 'd_model': 400, 'dff': 512, 'num_heads': 8, 'dropout_rate': 0.1, 'wp_d': 4, 'num_emb_vec': 4, 'bs': 16, 'dense_n': 512, 'num_dense': 3, 'concat_emb': False, 'features_n': 793, 'optimizer': 'adam', 'norm_layer': True, 'activation': 'tanh', 'loss': 'mse', 'sf': 1.0, 'augment': 0}\n",
      "loading weights:  /home/azureuser/data/models/ICRA_TF4D_dataset_size_aug/TF-num_layers_enc:1-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:1.0-augment:0.h5\n",
      "\n",
      "with next waypoint prediction\n",
      "605/605 [==============================] - 16s 22ms/step - loss: 9.7226e-05\n",
      "MSE:  9.695854532765225e-05\n",
      "---------------------------------------------------\n",
      "with autoregressive generation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [07:16<00:00, 11.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.002402131624049286\n",
      "Trajectory metrics:\n",
      "pcm:\t nan\n",
      "dfd:\t 0.057981619702562145\n",
      "area:\t 0.02590039823868204\n",
      "cl:\t nan\n",
      "dtw:\t 1.3980032322981384\n",
      "mae:\t 0.019107776578979774\n",
      "mse:\t 0.0010874291330305122\n",
      "======================================================================================================\n",
      "Dataset size:  100.0 %\t augmentation:  ON  \n",
      "\n",
      "{'num_layers_enc': 1, 'num_layers_dec': 5, 'd_model': 400, 'dff': 512, 'num_heads': 8, 'dropout_rate': 0.1, 'wp_d': 4, 'num_emb_vec': 4, 'bs': 16, 'dense_n': 512, 'num_dense': 3, 'concat_emb': False, 'features_n': 793, 'optimizer': 'adam', 'norm_layer': True, 'activation': 'tanh', 'loss': 'mse', 'sf': 1.0, 'augment': 1}\n",
      "loading weights:  /home/azureuser/data/models/ICRA_TF4D_dataset_size_aug/TF-num_layers_enc:1-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:1.0-augment:1.h5\n",
      "\n",
      "with next waypoint prediction\n",
      "605/605 [==============================] - 15s 22ms/step - loss: 9.7997e-05\n",
      "MSE:  9.754819620866328e-05\n",
      "---------------------------------------------------\n",
      "with autoregressive generation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [07:18<00:00, 11.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.002434250811546625\n",
      "Trajectory metrics:\n",
      "pcm:\t nan\n",
      "dfd:\t 0.06272383677183252\n",
      "area:\t 0.027304498562373426\n",
      "cl:\t nan\n",
      "dtw:\t 1.4905868040355599\n",
      "mae:\t 0.02052867658111762\n",
      "mse:\t 0.0012096910789396484\n"
     ]
    }
   ],
   "source": [
    "from src.TF4D_mult_features import *\n",
    "model_path = models_folder+\"ICRA_TF4D_dataset_size_aug/\"\n",
    "\n",
    "model_names =  [\"TF-num_layers_enc:1-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:0.01-augment:0.h5\",\n",
    "                \"TF-num_layers_enc:1-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:0.01-augment:1.h5\",\n",
    "                \"TF-num_layers_enc:1-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:0.1-augment:0.h5\",\n",
    "                \"TF-num_layers_enc:1-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:0.1-augment:1.h5\",\n",
    "                \"TF-num_layers_enc:1-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:1.0-augment:0.h5\",\n",
    "                \"TF-num_layers_enc:1-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:1.0-augment:1.h5\"]\n",
    "models_metrics = {}\n",
    "for model_name in model_names:\n",
    "\n",
    "    model_file = model_path+model_name\n",
    "    param = file_name2dict(model_file,delimiter=\"-\",show=False)\n",
    "    print(\"======================================================================================================\")\n",
    "    print(\"Dataset size: \",str(100.0*float(param[\"sf\"])),\"%\\t\",\"augmentation: \",\"ON \"if param['augment']==1 else \"OFF\", \"\\n\")\n",
    "    model_tag = \"size:\" + str(100.0*float(param[\"sf\"]))+\"_aug:\"+ str(param['augment'])\n",
    "\n",
    "    model = load_model(model_file, delimiter=\"-\")\n",
    "    metrics = evaluate_model(model, x_t, y_t)\n",
    "    models_metrics[model_tag] = metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Num of encoders, decoder and model depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.TF4D_mult_features import *\n",
    "model_path = models_folder+\"ICRA_TF4D_enc_dec_depth/\"\n",
    "\n",
    "model_names =  [\"TF-num_layers_enc:1-num_layers_dec:3-d_model:256-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:1.0-augment:1.h5\",\n",
    "                \"TF-num_layers_enc:1-num_layers_dec:3-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:1.0-augment:1.h5\",\n",
    "                \"TF-num_layers_enc:1-num_layers_dec:5-d_model:256-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:1.0-augment:1.h5\",\n",
    "                \"TF-num_layers_enc:1-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:1.0-augment:1.h5\",\n",
    "                \"TF-num_layers_enc:2-num_layers_dec:3-d_model:256-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:1.0-augment:1.h5\",\n",
    "                \"TF-num_layers_enc:2-num_layers_dec:3-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:1.0-augment:1.h5\",\n",
    "                \"TF-num_layers_enc:2-num_layers_dec:5-d_model:256-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:1.0-augment:1.h5\",\n",
    "                \"TF-num_layers_enc:2-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:4-bs:16-dense_n:512-num_dense:3-concat_emb:False-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse-sf:1.0-augment:1.h5\"]\n",
    "models_metrics_enc_dec = {}\n",
    "for model_name in model_names:\n",
    "\n",
    "    model_file = model_path+model_name\n",
    "    param = file_name2dict(model_file,delimiter=\"-\",show=False)\n",
    "    print(\"======================================================================================================\")\n",
    "    print(\"num Encoders: \",param[\"num_layers_enc\"],\"\\tnum Decoders: \",param[\"num_layers_dec\"],\"\\tDepth: \",param['d_model'])\n",
    "    model_tag = \"enc:\"+str(param[\"num_layers_enc\"])+\"-dec:\"+str(param[\"num_layers_dec\"])+\"-d\"+str(param['d_model'])\n",
    "\n",
    "    model = load_model(model_file, delimiter=\"-\")\n",
    "    metrics = evaluate_model(model, x_t, y_t)\n",
    "    models_metrics[model_tag] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clip only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1,3,256\n",
    "1,3,400\n",
    "1,5,256\n",
    "1,5,400\n",
    "2,3,256\n",
    "2,3,400\n",
    "2,5,256\n",
    "2,5,400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forces interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading BERT model... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "loading CLIP model... done\n",
      "DEVICE:  cuda\n",
      "loading dataset:  forces_only_f ...done\n",
      "raw X: (10000, 953) \tY: (10000, 160)\n",
      "filtered X: (10000, 953) \tY: (10000, 160)\n",
      "Train X: (7000, 953) \tY: (7000, 160)\n",
      "Test  X: (2000, 953) \tY: (2000, 160)\n",
      "Val   X: (1000, 953) \tY: (1000, 160)\n",
      "{'num_layers_enc': 1, 'num_layers_dec': 5, 'd_model': 400, 'dff': 512, 'num_heads': 8, 'dropout_rate': 0.1, 'wp_d': 4, 'num_emb_vec': 16, 'bs': 16, 'dense_n': 512, 'num_dense': 3, 'concat_emb': True, 'features_n': 793, 'optimizer': 'adam', 'norm_layer': True, 'activation': 'tanh', 'loss': 'mse'}\n",
      "loading weights:  /home/azureuser/data/models/forces_onl/TF-num_layers_enc:1-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:16-bs:16-dense_n:512-num_dense:3-concat_emb:True-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import numpy as np\n",
    "from src.motion_refiner_4D import Motion_refiner, MAX_NUM_OBJS\n",
    "from src.config import *\n",
    "from src.functions import *\n",
    "\n",
    "mr = Motion_refiner(load_models=True ,traj_n = traj_n, locality_factor=True, clip_only=False)\n",
    "feature_indices, obj_sim_indices, obj_poses_indices, traj_indices = mr.get_indices()\n",
    "embedding_indices = mr.embedding_indices\n",
    "\n",
    "#============================== load dataset ==========================================\n",
    "X,Y, data = mr.load_dataset(\"forces_only_f\", filter_data = True, base_path=data_folder)\n",
    "X_train, X_test, X_valid, y_train, y_test, y_valid, indices_train, indices_test, indices_val = mr.split_dataset(X, Y, test_size=0.2, val_size=0.1)\n",
    "\n",
    "\n",
    "def prepare_x(x):\n",
    "    objs = pad_array(list_to_wp_seq(x[:,obj_poses_indices],d=3),4,axis=-1) # no speed\n",
    "    trajs = list_to_wp_seq(x[:,traj_indices],d=4)\n",
    "    #   return np.concatenate([objs,trajs],axis = 1)\n",
    "    return trajs[:,:-1,:]\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((prepare_x(X_test),\n",
    "                                                    list_to_wp_seq(y_test,d=4),\n",
    "                                                    X_test[:,embedding_indices])).batch(X_test.shape[0])\n",
    "\n",
    "g = generator(test_dataset,stop=True,augment=False)\n",
    "x_t, y_t = next(g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_layers_enc': 1, 'num_layers_dec': 5, 'd_model': 400, 'dff': 512, 'num_heads': 8, 'dropout_rate': 0.1, 'wp_d': 4, 'num_emb_vec': 16, 'bs': 16, 'dense_n': 512, 'num_dense': 3, 'concat_emb': True, 'features_n': 793, 'optimizer': 'adam', 'norm_layer': True, 'activation': 'tanh', 'loss': 'mse'}\n",
      "loading weights:  /home/azureuser/data/models/forces_onl/TF-num_layers_enc:1-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:16-bs:16-dense_n:512-num_dense:3-concat_emb:True-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse.h5\n"
     ]
    }
   ],
   "source": [
    "from src.TF4D_decoder_only import *\n",
    "\n",
    "model_path = models_folder+\"forces_onl/\"\n",
    "model_name = \"TF-num_layers_enc:1-num_layers_dec:5-d_model:400-dff:512-num_heads:8-dropout_rate:0.1-wp_d:4-num_emb_vec:16-bs:16-dense_n:512-num_dense:3-concat_emb:True-features_n:793-optimizer:adam-norm_layer:True-activation:tanh-loss:mse.h5\"\n",
    "\n",
    "model_file = model_path+model_name\n",
    "model = load_model(model_file, delimiter=\"-\")\n",
    "\n",
    "# metrics = evaluate_model(model, x_t, y_t)\n",
    "# models_metrics[model_tag] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 22:48:38.680329: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-09-12 22:48:38.680738: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2593990000 Hz\n",
      "2022-09-12 22:48:40.706933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "show_data4D() got an unexpected keyword argument 'plot_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1626149/323085439.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# pred_t = np.transpose(pred[:,:,:2],[0,2,1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mshow_data4D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_traj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_img_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"/home/mirmi/Arthur/dataset/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/home/tum/data/image_dataset/\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# show_data4D(data_sample,plot_output=False)#,image_loader=mr.image_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: show_data4D() got an unexpected keyword argument 'plot_output'"
     ]
    }
   ],
   "source": [
    "pred_d = np.array(data)[indices_test]\n",
    "for i,d in enumerate(pred_d):\n",
    "    d[\"forces\"] = pred[i]\n",
    "# plt.close('all')\n",
    "# indices = np.random.choice(range(len(indices_test)), 6)\n",
    "# pred_t = np.transpose(pred[:,:,:2],[0,2,1])\n",
    "\n",
    "show_data4D(pred_d,plot_output=False,image_loader=mr.image_loader, color_traj=False, change_img_base=[\"/home/mirmi/Arthur/dataset/\",\"/home/tum/data/image_dataset/\"])\n",
    "# show_data4D(data_sample,plot_output=False)#,image_loader=mr.image_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('py_38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b62a40e8dd7000646b6963e02e99a765b1ed754b7d58fb490e5b150559f544e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
